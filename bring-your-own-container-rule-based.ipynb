{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Make your own container from base image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering the container\n",
    "\n",
    "The following shell code shows how to build the container image using `docker build` and push the container image to ECR using `docker push`. \n",
    "\n",
    "This code looks for an ECR repository in the account you're using and the current region. If the repository doesn't exist, the script will create it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = \"111016121260.dkr.ecr.us-east-2.amazonaws.com/ubuntu-16.04-base-with-pip\"\n",
    "%env base_image=$base_image\n",
    "\n",
    "#create Dockerfile with base image\n",
    "!echo FROM $base_image > container_rule/Dockerfile\n",
    "!echo >> container_rule/Dockerfile\n",
    "!echo \"ENV PYTHONUNBUFFERED=TRUE\" >> container_rule/Dockerfile\n",
    "!echo \"ENV PYTHONDONTWRITEBYTECODE=TRUE\" >> container_rule/Dockerfile\n",
    "!echo \"ENV PATH=\\\"/opt/program:\\${PATH}\\\"\" >> container_rule/Dockerfile\n",
    "!echo >> container_rule/Dockerfile\n",
    "!echo \"COPY code\" /opt/program >> container_rule/Dockerfile\n",
    "!echo \"WORKDIR /opt/program\" >> container_rule/Dockerfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm name as environment viariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name=\"python-rule-based-1\"\n",
    "%env algorithm_name=$algorithm_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get account info for Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_account=!aws sts get-caller-identity --query Account --output text --endpoint-url https://sts.us-east-2.amazonaws.com\n",
    "account = get_account[0]\n",
    "%env account=$account\n",
    "\n",
    "get_region=!aws configure get region\n",
    "region = get_region[0]\n",
    "%env region=$region\n",
    "\n",
    "fullname=f\"{account}.dkr.ecr.{region}.amazonaws.com/{algorithm_name}:latest\"\n",
    "%env fullname=$fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set permission for folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x container_rule/code/serve\n",
    "\n",
    "!ls -latr container_rule/code/serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ECR repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "echo \"completed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out created ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr describe-repositories --repository-names \"$algorithm_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, run the below command to take a look at the Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat container_rule/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below code will login to ECR and then build the docker image and push to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cd container_rule\n",
    "pwd\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region $region --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t $algorithm_name .\n",
    "docker tag $algorithm_name $fullname\n",
    "\n",
    "docker push $fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out docker image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images $algorithm_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using your Algorithm in Amazon SageMaker\n",
    "\n",
    "Once you have your container packaged, you can use it to train models and use the model for hosting or batch transforms. Let's do that with the algorithm we made above.\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Here we specify a bucket to use and the role that will be used for working with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker as sage\n",
    "\n",
    "# add role being used by notebook\n",
    "role =\"arn:aws:iam::111016121260:role/service-role/SC-111016121260-pp-6qlynp56-SageMakerExecutionRole-1KR1D7OKE5RN0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting your model\n",
    "You can use a trained model to get real time predictions using HTTP endpoint. Follow these steps to walk you through the process.\n",
    "\n",
    "### Deploy the model\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = 100\n",
    "\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "#model.Model\n",
    "toc = time.time()\n",
    "model = sage.model.Model(model_data=\"\",image=image,role=role)\n",
    "model.deploy(initial_instance_count=1,instance_type=\"ml.m4.xlarge\",wait=False)\n",
    "tic = time.time()\n",
    "\n",
    "timer = tic - toc\n",
    "print(\"\")\n",
    "print(f\"Time took to complete: {timer} seconds or {timer/60} minutes\")\n",
    "\n",
    "print(model.name)\n",
    "\n",
    "#transformer.Transformer\n",
    "toc = time.time()\n",
    "transform = sage.transformer.Transformer(model_name=model.name,instance_count=1,instance_type=\"ml.c4.xlarge\", max_payload=10, max_concurrent_transforms=10, strategy='MultiRecord')\n",
    "transform.transform(data=\"s3://sagemaker-cfn/\" +  str(sample_count) + \"-sample.csv\", content_type='text/csv', split_type='Line',wait=True)\n",
    "#model.deploy(initial_instance_count=1,instance_type=\"ml.m4.xlarge\", wait=False)\n",
    "tic = time.time()\n",
    "\n",
    "timer = tic - toc\n",
    "print(\"\")\n",
    "print(f\"Time took to complete: {timer} seconds or {timer/60} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send data though endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get endpoint name that was just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker list-endpoints --name-contains $algorithm_name \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sagemaker = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def invoke_ep(event):\n",
    "    \n",
    "    response = sagemaker.invoke_endpoint(EndpointName=\"python-rule-based-1-2020-03-22-20-11-21-981\", # add endpoint here\n",
    "                                       ContentType='text/csv',\n",
    "                                       #Body=https://sagemaker-cfn.s3.us-east-2.amazonaws.com/channels+(1).csv)\n",
    "                                       Body=event)\n",
    "\n",
    "    result = response['Body'].read().decode()\n",
    "    #result = json.loads(response['Body'].read().decode())\n",
    "    print(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "invoke_ep(b\"12.01,14.05\\n14.2,12.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker list-transform-jobs --name-contains $algorithm_name --query TransformJobSummaries[*].[TransformJobName,TransformJobArn,TransformJobStatus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker describe-transform-job --transform-job-name python-rule-based-1-2020-03-22-20-11-22-474\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
