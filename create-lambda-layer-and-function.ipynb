{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Make lambda layers, lambda function, and execute function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firtst, lets create a few sample files in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "lambda_c = boto3.client('lambda')\n",
    "\n",
    "sample_count = 10000000 #enter sample count\n",
    "sample_file_s3 = 'sagemaker-cfn' #enter sample file s3 bucket name\n",
    "bucket_layer = \"lambda-layer-for-python\" # add your bucket name and needs to be same region as the lambda function\n",
    "sample_file_s3_name = str(sample_count) + '-sample.csv' # modify if needed\n",
    "sample_file_s3_name_out = str(sample_count) + '-sample-out' # modify if needed\n",
    "\n",
    "df = pd.DataFrame(numpy.random.randint(12000,15000,size=(sample_count, 2)).astype(\"float\")/1000)\n",
    "out = StringIO()\n",
    "pd.DataFrame({'0':df[0],'1':df[1]}).to_csv(out, header=False, index=False)\n",
    "result = out.getvalue()\n",
    "\n",
    "#bucket = s3.Bucket(sample_file_s3)\n",
    "s3.Object(sample_file_s3, sample_file_s3_name).put(Body=result) # Ensure status code is 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install lambda-layer using pip. Ensure kernel is conda_python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lambda-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide layer name, version and the layer to be installed via pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name=\"numpy\"\n",
    "layer_version=\"0.0.1\"\n",
    "layer=\"numpy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating env vairables\n",
    "%env layer_name=$layer_name\n",
    "%env layer_version=$layer_version\n",
    "%env layer=$layer\n",
    "\n",
    "# creating config file\n",
    "!printf \"[[layers]]\\n name = \\\"$layer_name\\\"\\n version = \\\"$layer_version\\\"\\n packages = [\\n     '$layer'\\n]\" > req.txt\n",
    "!cat req.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=!lambda-layer package -c req.txt |grep \"Copying\" |awk '{print $4}'\n",
    "layer_output = output[0]\n",
    "layer_output_name = layer_output.split(\"/\")[-1]\n",
    "print(f\"Created {layer_output_name} at {layer_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your lambda layer is created. But you dont need it. Lets download aws-data-wrangler.\n",
    "\n",
    "via below link:\n",
    "\n",
    "https://github.com/awslabs/aws-data-wrangler/releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check version\n",
    "wr_path = \"https://github.com/awslabs/aws-data-wrangler/releases/download/0.3.2/awswrangler-layer-0.3.2-py3.8.zip\"\n",
    "wr_name = wr_path.split(\"/\")[-1]\n",
    "wr_name_short = wr_path.split(\"/\")[-1].split(\"-\")[0]\n",
    "\n",
    "%env wr_path=$wr_path\n",
    "%env wr_name=$wr_name\n",
    "%env wr_name_short=$wr_name_short\n",
    "\n",
    "!wget $wr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_region=!aws configure get region\n",
    "region = get_region[0]\n",
    "%env region=$region\n",
    "%env bucket_layer=$bucket_layer\n",
    "\n",
    "s3_path1 = s3.Bucket(bucket_layer).upload_file(layer_output, layer_output_name)\n",
    "s3_path2 = s3.Bucket(bucket_layer).upload_file(wr_name, wr_name)\n",
    "\n",
    "for files in s3.Bucket(bucket_layer).objects.all():\n",
    "    print(f\"https://{files.bucket_name}.s3.{region}.amazonaws.com/{files.key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the below command to publish the lambda layer.  Copy the ouput and paste into cfn-lambda.template like described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "        \"AWSWRLambda\": {\n",
    "            \"Type\": \"AWS::Lambda::Function\",\n",
    "                ........\n",
    "                \"Timeout\": 900,\n",
    "                \"Handler\": \"lambda_function.lambda_handler\",\n",
    "                \"Runtime\": \"python3.8\",\n",
    "                \"MemorySize\": 3000,\n",
    "                \"Layers\": [\"COPY ARN HERE\"] <---\n",
    "            }\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Copy the below output to cfn-lambda.template\"\n",
    "!aws lambda publish-layer-version \\\n",
    "    --layer-name $wr_name_short \\\n",
    "    --description $wr_name \\\n",
    "    --license-info \"MIT\" \\\n",
    "    --content S3Bucket=$BUCKET_layer,S3Key=$wr_name \\\n",
    "    --compatible-runtimes python3.8 \\\n",
    "    --region $region \\\n",
    "    --query LayerVersionArn\n",
    "layer_versions=!aws lambda list-layer-versions --layer-name $wr_name_short --query LayerVersions[0].[Version][0]\n",
    "layer_version=layer_versions[0]\n",
    "%env layer_version=$layer_version\n",
    "layer_arns=!aws lambda get-layer-version --layer-name $wr_name_short --version-number $layer_version --query LayerVersionArn\n",
    "layer_arn=layer_arns[0].replace('\"','')\n",
    "%env layer_arn=$layer_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws lambda get-layer-version --layer-name $wr_name_short --version-number $layer_version --query LayerVersionArn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy python code to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_function = \"lambda-function-for-python\" # add your bucket name and needs to be in region of the lambda function\n",
    "%env BUCKET_function=$BUCKET_function\n",
    "!rm lambda_function.zip\n",
    "!zip lambda_function.zip lambda_function.py\n",
    "s3_path = s3.Bucket(BUCKET_function).upload_file(\"lambda_function.zip\", \"lambda_function.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add bucket details to cfn-lambda.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "        \"AWSWRLambda\": {\n",
    "            \"Type\": \"AWS::Lambda::Function\",\n",
    "            ........\n",
    "            \"Properties\": {\n",
    "                \"Code\": {\n",
    "                    \"S3Bucket\": \"ENTER BUCKET NAME\", <----\n",
    "                    \"S3Key\": \"lambda-function.zip\"\n",
    "                },\n",
    "             .......\n",
    "            }\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda layer is now published and we can make the lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws cloudformation create-stack --template-body file://cfn-lambda.template --stack-name cfn-lambda --parameters ParameterKey=bucket,ParameterValue=$BUCKET_function ParameterKey=layer,ParameterValue=$layer_arn --capabilities CAPABILITY_IAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep running the below command until an output with \"CREATE_COMPLETE\" is generated. Around 2 min.  Copy the arn to the below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws cloudformation describe-stacks --stack-name cfn-lambda --query Stacks[*][StackName,StackStatus,Outputs[*].[OutputValue]]\n",
    "lambda_arns=!aws cloudformation describe-stacks --stack-name cfn-lambda --query Stacks[*][StackName,StackStatus,Outputs[*].[OutputValue]] | grep arn | sed -e 's/^\\s*//' -e '/^$/d'\n",
    "lambda_arn = lambda_arns[0].replace('\"',\"\")\n",
    "%env lambda_arn=$lambda_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = '{ \"input\": \"s3://sagemaker-cfn/' + sample_file_s3_name + '\", \"output\":\"s3://sagemaker-cfn/' + sample_file_s3_name_out + '\" }'\n",
    "response = lambda_c.invoke(\n",
    "    FunctionName=lambda_arn,\n",
    "    InvocationType='RequestResponse',\n",
    "    LogType='Tail',\n",
    "    Payload=payload\n",
    ")\n",
    "\n",
    "print(response['StatusCode'])\n",
    "print(response['Payload'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
